import cv2
import dlib
import numpy as np
import speech_recognition as sr
from pydub import AudioSegment
from pydub.playback import play
import random
import string

# Load face detector and shape predictor from dlib
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("/Users/jyotiradityachopra/Downloads/shape_predictor_68_face_landmarks.dat")  # Path to the shape predictor file

# Initialize variables for eye aspect ratio and cheating detection
eye_aspect_ratio_threshold = 0.3
consecutive_frames_for_cheating = 20
consecutive_cheat_frames = 0

# Initialize the speech recognizer
recognizer = sr.Recognizer()

# Function to play sound effects using pydub
def play_sound(filename):
    sound = AudioSegment.from_file(filename)
    play(sound)

# Function to generate a random captcha
def generate_captcha():
    captcha = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))
    return captcha

# Function to calculate eye aspect ratio
def eye_aspect_ratio(eye):
    # Calculate the euclidean distances between the two sets of vertical eye landmarks
    A = np.linalg.norm(eye[1] - eye[5])
    B = np.linalg.norm(eye[2] - eye[4])

    # Calculate the euclidean distance between the horizontal eye landmarks
    C = np.linalg.norm(eye[0] - eye[3])

    # Compute the eye aspect ratio
    ear = (A + B) / (2.0 * C)

    return ear

# Start capturing video from the default camera (usually 0)
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()

    if not ret:
        break

    # Convert the frame to grayscale for face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces in the grayscale frame
    faces = detector(gray)

    for face in faces:
        # Detect facial landmarks
        shape = predictor(gray, face)
        shape = np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)])

        # Extract eye coordinates
        left_eye = shape[36:42]
        right_eye = shape[42:48]

        # Calculate eye aspect ratio for left and right eyes
        left_ear = eye_aspect_ratio(left_eye)
        right_ear = eye_aspect_ratio(right_eye)

        # Average of both eyes' aspect ratio
        ear = (left_ear + right_ear) / 2.0

        # Check for cheating
        if ear < eye_aspect_ratio_threshold:
            consecutive_cheat_frames += 1
            if consecutive_cheat_frames >= consecutive_frames_for_cheating:
                print("Cheating detected! Eyes are moving.")
                play_sound("/Users/jyotiradityachopra/Documents/my cheating detection/cheating_alert.mp3")

                # Generate and display captcha
                captcha = generate_captcha()
                print(f"Enter the captcha: {captcha}")

                # Recognize voice input to check if cheating is confirmed
                with sr.Microphone() as source:
                    print("Say the captcha:")
                    audio = recognizer.listen(source)

                try:
                    voice_input = recognizer.recognize_google(audio).upper()
                    if voice_input == captcha:
                        print("Captcha confirmed. Cheating not confirmed.")
                    else:
                        print("Incorrect captcha. Cheating confirmed!")
                except sr.UnknownValueError:
                    print("Could not understand audio.")
                except sr.RequestError as e:
                    print(f"Could not request results; {e}")

        else:
            consecutive_cheat_frames = 0

    # Display the frame
    cv2.imshow("Eye Tracking", frame)

    # Break the loop if 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture object
cap.release()
cv2.destroyAllWindows()
